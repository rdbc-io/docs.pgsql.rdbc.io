{
    "docs": [
        {
            "location": "/",
            "text": "What is rdbc-pgsql?\n\u00b6\n\n\nrdbc-pgsql is a \nnetty\n based \nrdbc\n driver\nfor PostgreSQL allowing asynchronous communication with the database in Scala\nand Java languages.\n\n\nrdbc API\n\u00b6\n\n\nYou'll be using this PostgreSQL driver via the database vendor agnostic API which\nusage is not covered by this documentation. This guide describes things that\nare specific to the driver itself. Please head to the \nAPI documentation site\n\nfor detailed information on API usage and general rdbc concepts.\n\n\nSupported PostrgreSQL versions\n\u00b6\n\n\nThe driver aims to support two latest stable PostgreSQL versions. Currently\nit means supporting PostgreSQL 10.x and 9.6.x. The driver is tested\nagainst only these two versions but in fact, it should work with all versions \nsince 7.4.\n\n\nGetting help\n\u00b6\n\n\nJoin \nrdbc-io/rdbc\n gitter channel for \nquestions and any kind of discussion about rdbc and the driver.\n\n\nSee also \nrdbc\n\ntag on StackOverflow.\n\n\nLicense\n\u00b6\n\n\nrdbc-pgsql is an open source software licensed under\n\nApache License 2.0\n.",
            "title": "Introduction"
        },
        {
            "location": "/#what-is-rdbc-pgsql",
            "text": "rdbc-pgsql is a  netty  based  rdbc  driver\nfor PostgreSQL allowing asynchronous communication with the database in Scala\nand Java languages.",
            "title": "What is rdbc-pgsql?"
        },
        {
            "location": "/#rdbc-api",
            "text": "You'll be using this PostgreSQL driver via the database vendor agnostic API which\nusage is not covered by this documentation. This guide describes things that\nare specific to the driver itself. Please head to the  API documentation site \nfor detailed information on API usage and general rdbc concepts.",
            "title": "rdbc API"
        },
        {
            "location": "/#supported-postrgresql-versions",
            "text": "The driver aims to support two latest stable PostgreSQL versions. Currently\nit means supporting PostgreSQL 10.x and 9.6.x. The driver is tested\nagainst only these two versions but in fact, it should work with all versions \nsince 7.4.",
            "title": "Supported PostrgreSQL versions"
        },
        {
            "location": "/#getting-help",
            "text": "Join  rdbc-io/rdbc  gitter channel for \nquestions and any kind of discussion about rdbc and the driver.  See also  rdbc \ntag on StackOverflow.",
            "title": "Getting help"
        },
        {
            "location": "/#license",
            "text": "rdbc-pgsql is an open source software licensed under Apache License 2.0 .",
            "title": "License"
        },
        {
            "location": "/scala/installation/",
            "text": "Adding rdbc-pgsql to your project\n\u00b6\n\n\nrdbc and rdbc-pgsql JARs are published to\n\nMaven Central\n\nrepository. The library is currently available for Scala 2.11 and 2.12 and requires\nJava 8 runtime. rdbc-pgsql targets {{rdbc_version}} rdbc API version.\n\n\nSBT\n\u00b6\n\n\nFor sbt projects, add the following to \nbuild.sbt\n:\n\n\nlibraryDependencies\n \n++=\n \nVector\n(\n\n  \n\"io.rdbc\"\n \n%%\n \n\"rdbc-api-scala\"\n \n%\n \n\"{{rdbc_version}}\"\n,\n\n  \n\"io.rdbc.pgsql\"\n \n%%\n \n\"pgsql-transport-netty\"\n \n%\n \n\"{{version}}\"\n\n\n)\n\n\n\n\n\n\nGradle\n\u00b6\n\n\nFor Gradle projects, add the following to the \ndependencies\n section of \nbuild.gradle\n:\n\n\nScala 2.12\n\n\ncompile\n \ngroup:\n \n'io.rdbc'\n,\n \nname:\n \n'rdbc-api-scala_2.12'\n,\n \nversion:\n \n'{{rdbc_version}}'\n\n\ncompile\n \ngroup:\n \n'io.rdbc.pgsql'\n,\n \nname:\n \n'pgsql-transport-netty_2.12'\n,\n \nversion:\n \n'{{version}}'\n\n\n\n\n\n\nScala 2.11\n\n\ncompile\n \ngroup:\n \n'io.rdbc'\n,\n \nname:\n \n'rdbc-api-scala_2.11'\n,\n \nversion:\n \n'{{rdbc_version}}'\n\n\ncompile\n \ngroup:\n \n'io.rdbc.pgsql'\n,\n \nname:\n \n'pgsql-transport-netty_2.11'\n,\n \nversion:\n \n'{{version}}'\n\n\n\n\n\n\nMaven\n\u00b6\n\n\nFor Maven projects, add the following to the \ndependencies\n element of \npom.xml\n:\n\n\nScala 2.12\n\n\n<dependency>\n\n  \n<groupId>\nio.rdbc\n</groupId>\n\n  \n<artifactId>\nrdbc-api-scala_2.12\n</artifactId>\n\n  \n<version>\n{{rdbc_version}}\n</version>\n\n\n</dependency>\n\n\n<dependency>\n\n  \n<groupId>\nio.rdbc.pgsql\n</groupId>\n\n  \n<artifactId>\npgsql-transport-netty_2.12\n</artifactId>\n\n  \n<version>\n{{version}}\n</version>\n\n\n</dependency>\n\n\n\n\n\n\nScala 2.11\n\n\n<dependency>\n\n  \n<groupId>\nio.rdbc\n</groupId>\n\n  \n<artifactId>\nrdbc-api-scala_2.11\n</artifactId>\n\n  \n<version>\n{{rdbc_version}}\n</version>\n\n\n</dependency>\n\n\n<dependency>\n\n  \n<groupId>\nio.rdbc.pgsql\n</groupId>\n\n  \n<artifactId>\npgsql-transport-netty_2.11\n</artifactId>\n\n  \n<version>\n{{version}}\n</version>\n\n\n</dependency>",
            "title": "Installation"
        },
        {
            "location": "/scala/installation/#adding-rdbc-pgsql-to-your-project",
            "text": "rdbc and rdbc-pgsql JARs are published to Maven Central \nrepository. The library is currently available for Scala 2.11 and 2.12 and requires\nJava 8 runtime. rdbc-pgsql targets {{rdbc_version}} rdbc API version.",
            "title": "Adding rdbc-pgsql to your project"
        },
        {
            "location": "/scala/installation/#sbt",
            "text": "For sbt projects, add the following to  build.sbt :  libraryDependencies   ++=   Vector ( \n   \"io.rdbc\"   %%   \"rdbc-api-scala\"   %   \"{{rdbc_version}}\" , \n   \"io.rdbc.pgsql\"   %%   \"pgsql-transport-netty\"   %   \"{{version}}\"  )",
            "title": "SBT"
        },
        {
            "location": "/scala/installation/#gradle",
            "text": "For Gradle projects, add the following to the  dependencies  section of  build.gradle :  Scala 2.12  compile   group:   'io.rdbc' ,   name:   'rdbc-api-scala_2.12' ,   version:   '{{rdbc_version}}'  compile   group:   'io.rdbc.pgsql' ,   name:   'pgsql-transport-netty_2.12' ,   version:   '{{version}}'   Scala 2.11  compile   group:   'io.rdbc' ,   name:   'rdbc-api-scala_2.11' ,   version:   '{{rdbc_version}}'  compile   group:   'io.rdbc.pgsql' ,   name:   'pgsql-transport-netty_2.11' ,   version:   '{{version}}'",
            "title": "Gradle"
        },
        {
            "location": "/scala/installation/#maven",
            "text": "For Maven projects, add the following to the  dependencies  element of  pom.xml :  Scala 2.12  <dependency> \n   <groupId> io.rdbc </groupId> \n   <artifactId> rdbc-api-scala_2.12 </artifactId> \n   <version> {{rdbc_version}} </version>  </dependency>  <dependency> \n   <groupId> io.rdbc.pgsql </groupId> \n   <artifactId> pgsql-transport-netty_2.12 </artifactId> \n   <version> {{version}} </version>  </dependency>   Scala 2.11  <dependency> \n   <groupId> io.rdbc </groupId> \n   <artifactId> rdbc-api-scala_2.11 </artifactId> \n   <version> {{rdbc_version}} </version>  </dependency>  <dependency> \n   <groupId> io.rdbc.pgsql </groupId> \n   <artifactId> pgsql-transport-netty_2.11 </artifactId> \n   <version> {{version}} </version>  </dependency>",
            "title": "Maven"
        },
        {
            "location": "/scala/connection_factory/",
            "text": "As rdbc documentation \nmentions\n,\nto use the API you need to construct a driver specific \nConnectionFactory\n \nimplementation. In rdbc-pgsql case, it's going to be\n\nNettyPgConnectionFactory\n.\n\n\nTo instantiate \nNettyPgConnectionFactory\n use its companion object's \napply\n\nmethod. This factory method accepts a configuration object \u2014 \n\nNettyPgConnFactory#Config\n instance. Chapters below focus on providing\nthe configuration.\n\n\nSimple scenario\n\u00b6\n\n\nTo create a configuration instance with default configuration options\nuse \nNettyPgConnFactory#Config\n's \napply\n method with \nhost\n, \nport\n and\n\nauthenticator\n parameters:\n\n\nimport\n \nio.rdbc.pgsql.transport.netty.NettyPgConnectionFactory\n\n\nimport\n \nio.rdbc.pgsql.transport.netty.NettyPgConnectionFactory.Config\n\n\nimport\n \nio.rdbc.pgsql.core.auth.Auth\n\n\n\nval\n \ncf\n \n=\n \nNettyPgConnectionFactory\n(\n\n  \nConfig\n(\n\n    \nhost\n \n=\n \n\"localhost\"\n,\n\n    \nport\n \n=\n \n5432\n,\n\n    \nauthenticator\n \n=\n \nAuth\n.\npassword\n(\n\"user\"\n,\n \n\"pass\"\n)\n\n  \n)\n\n\n)\n\n\n\n\n\n\nIf you want to tweak some configuration options (and most likely you do) read\nthe paragraph below.\n\n\nConfiguration options\n\u00b6\n\n\nIf you want to override some of default option values use named parameters\nof \nConfig.apply\n method. In the example below \ndbName\n option is changed\nfrom default \nNone\n to \nSome(\"db\")\n. \n\n\nimport\n \nio.rdbc.pgsql.transport.netty.NettyPgConnectionFactory\n\n\nimport\n \nio.rdbc.pgsql.transport.netty.NettyPgConnectionFactory.Config\n\n\nimport\n \nio.rdbc.pgsql.core.auth.Auth\n\n\n\nval\n \ncf\n \n=\n \nNettyPgConnectionFactory\n(\nConfig\n(\n\n  \nhost\n \n=\n \n\"localhost\"\n,\n\n  \nport\n \n=\n \n5432\n,\n\n  \nauthenticator\n \n=\n \nAuth\n.\npassword\n(\n\"user\"\n,\n \n\"pass\"\n),\n\n  \ndbName\n \n=\n \nSome\n(\n\"db\"\n)\n\n\n))\n\n\n\n\n\n\nFor other examples see \nexamples\n paragraph.\n\n\nThe paragraphs below list available configuration options.\n\n\nNon-transport specific options\n\u00b6\n\n\nThe driver is designed to support multiple transport libraries. This paragraph lists\noptions non-specific to any transport library.\n\n\nFrequently used\n\u00b6\n\n\n\n\n\n\nhost\n\n\nHost name or IP address the database listens on.\n\n\nDefault value: no default value.\n\n\n\n\n\n\n\n\n\n\n\n\nport\n\n\nTCP port the database listens on.\n\n\nDefault value: no default value.\n\n\n\n\n\n\n\n\n\n\n\n\nauthenticator\n\n\nAuthenticator\n instance performing authentication. See\n \nauthentication\n chapter for details.\n\n\nDefault value: no default value.\n\n\n\n\n\n\n\n\n\n\n\n\ndbName\n\n\nThe database name. if \nNone\n is provided database name will be assumed to\n be the same as user name provide by the authenticator.\n\n\nDefault value: \nNone\n.\n\n\n\n\n\n\n\n\n\n\n\n\nsubscriberBufferCapacity\n\n\nWhen streaming data from client to the database the driver can accumulate\n statements into batches for optimized execution. This parameter sets maximum\n number of statements that will be accumulated.\n\n\nDefault value: \n100\n.\n\n\n\n\n\n\n\n\n\n\n\n\nstmtCacheConfig\n\n\nConnection can cache prepared statements so that they can be reused when\n executed later on with different parameters. This paramaeter configures\n caching mechanism.\n\n\nPossible values:\n\n\n\n\nStmtCacheConfig\n.\nDisabled\n \u2014 disables caching\n\n\n\n\nStmtCacheConfig\n.\nEnabled\n \u2014 enables caching. \nEnabled\n case class\n       has following fields:\n\n\n\n\n\n\ncapacity\n\n\nSpecifies maximum prepared statements that can be cached.\n\n\n\n\n\n\n\n\n\n\nDefault value: \nEnabled\n(\ncapacity\n \n=\n \n100\n)\n.\n\n\n\n\n\n\n\n\n\n\n\n\nwriteTimeout\n\n\nIf socket write operation takes longer than this value, timeout error will be reported.\n\n\nDefault value: \nTimeout\n(\n10.\nseconds\n)\n.\n\n\n\n\n\n\n\n\n\n\n\n\nec\n\n\nExecution context used by the connection to execute \nFuture\n callbacks.\n\n\nDefault value: \nscala\n.\nconcurrent\n.\nExecutionContext\n.\nglobal\n.\n\n\n\n\n\n\nOther\n\u00b6\n\n\n\n\n\n\ntypeConverters\n\n\nColumn values and statement arguments have some nominal Scala types that\n directly correspond to PostgreSQL types. Converters specified here will \n convert between the nominal type and the type specified by the client. \n For example, \nint4\n column is nominally represented by \nPgInt4\n class but \n because there is a converter that can convert between \nPgInt4\n and \nInt\n\n whenever a \nPgInt4\n is expected client can supply an \nInt\n.\n\n\nConverters specified here supplement built-in converters.\n\n\nDefault value: \nVector\n.\nempty\n.\n\n\n\n\n\n\n\n\n\n\n\n\ntypeMappings\n\n\nStatement arguments have some nominal types that directly correspond\n to PostgreSQL types. If non-nominal type is used as a statement argument\n there has to be a mapping between this type and a nominal type. For instance,\n \nString\n maps to \nPgText\n type.\n\n\nType mappings specified there supplement built-in mappings.\n\n\nDefault value: \nVector\n.\nempty\n.\n\u00b6\n\n\n\n\n\n\ntypeCodecs\n\n\nCodecs for PostgreSQL types not supported by default by the driver. \n\n\nCodecs specified here supplement built-in codecs.\n\n\nDefault value: \nVector\n.\nempty\n.\n\n\n\n\n\n\n\n\n\n\n\n\nsubscriberMinDemandRequestSize\n\n\nWhen streaming data from a client to a database the driver requests statement\n argument sets from the client. This parameter defines minimum number of argument\n sets that the driver will request, each time the driver decides that it needs\n more argument sets.\n\n\nDefault value: \n10\n.\n\n\n\n\n\n\nNetty transport specific options\n\u00b6\n\n\n\n\n\n\nchannelFactory\n\n\nNetty \nChannelFactory\n that will be used to create a channel.\n\n\nBy default JDK NIO will be used which is supported on all platforms.\n Consider using platform specific native netty transport if your platform\n supports any. See \nthis\n\n page for details.\n\n\nDefault value: \nnew\n \nNioChannelFactory\n\n\n\n\n\n\n\n\n\n\n\n\neventLoopGroup\n\n\nNetty \nEventLoopGroup\n which will be used to handle events for the channel.\n\n\nBy default JDK NIO will be used which is supported on all platforms.\n Consider using platform specific native netty transport if your platform\n supports any. See \nthis\n\n page for details.\n\n\nDefault value: \nnew\n \nNioEventLoopGroup\n.\n\n\n\n\n\n\n\n\n\n\n\n\nchannelOptions\n\n\nNetty channel options.\n\n\nCONNECT_TIMEOUT_MILLIS\n is always ignored because it's overridden by\n timeout value passed to factory's \nconnection()\n method. Other than that,\n you can set any netty channel option here.\n\n\nDefault values:\n\n\n\n\nSO_KEEPALIVE = true\n\n\n\n\n\n\n\n\nExamples\n\u00b6\n\n\nCode in the snippet below creates a connection factory setting transport independent\n\nwriteTimeout\n and \nsubscriberBufferCapacity\n options and also setting netty-specific\n\nchannelOptions\n option.\n\n\nimport\n \nio.rdbc.pgsql.transport.netty.ChannelOptions._\n\n\nimport\n \nio.rdbc.pgsql.transport.netty.NettyPgConnectionFactory\n\n\nimport\n \nio.rdbc.pgsql.transport.netty.NettyPgConnectionFactory.Config\n\n\nimport\n \nio.rdbc.pgsql.core.auth.Auth\n\n\nimport\n \nio.rdbc.sapi.Timeout\n\n\nimport\n \nio.netty.channel.ChannelOption._\n\n\nimport\n \nscala.concurrent.duration._\n\n\n\nval\n \ncf\n \n=\n \n{\n\n  \nNettyPgConnectionFactory\n(\n\n    \nConfig\n(\n\n      \nhost\n \n=\n \n\"pg.example.com\"\n,\n\n      \nport\n \n=\n \n5432\n,\n\n      \nauthenticator\n \n=\n \nAuth\n.\npassword\n(\n\"user\"\n,\n \n\"pass\"\n),\n\n      \nwriteTimeout\n \n=\n \nTimeout\n(\n5.\nseconds\n),\n\n      \nsubscriberBufferCapacity\n \n=\n \n1000\n,\n\n      \nchannelOptions\n \n=\n \nVector\n(\n\n        \nSO_KEEPALIVE\n \n->\n \ntrue\n,\n\n        \nWRITE_SPIN_COUNT\n \n->\n \n3\n\n      \n)\n\n    \n)\n\n  \n)\n\n\n}",
            "title": "Constructing connection factory"
        },
        {
            "location": "/scala/connection_factory/#simple-scenario",
            "text": "To create a configuration instance with default configuration options\nuse  NettyPgConnFactory#Config 's  apply  method with  host ,  port  and authenticator  parameters:  import   io.rdbc.pgsql.transport.netty.NettyPgConnectionFactory  import   io.rdbc.pgsql.transport.netty.NettyPgConnectionFactory.Config  import   io.rdbc.pgsql.core.auth.Auth  val   cf   =   NettyPgConnectionFactory ( \n   Config ( \n     host   =   \"localhost\" , \n     port   =   5432 , \n     authenticator   =   Auth . password ( \"user\" ,   \"pass\" ) \n   )  )   If you want to tweak some configuration options (and most likely you do) read\nthe paragraph below.",
            "title": "Simple scenario"
        },
        {
            "location": "/scala/connection_factory/#configuration-options",
            "text": "If you want to override some of default option values use named parameters\nof  Config.apply  method. In the example below  dbName  option is changed\nfrom default  None  to  Some(\"db\") .   import   io.rdbc.pgsql.transport.netty.NettyPgConnectionFactory  import   io.rdbc.pgsql.transport.netty.NettyPgConnectionFactory.Config  import   io.rdbc.pgsql.core.auth.Auth  val   cf   =   NettyPgConnectionFactory ( Config ( \n   host   =   \"localhost\" , \n   port   =   5432 , \n   authenticator   =   Auth . password ( \"user\" ,   \"pass\" ), \n   dbName   =   Some ( \"db\" )  ))   For other examples see  examples  paragraph.  The paragraphs below list available configuration options.",
            "title": "Configuration options"
        },
        {
            "location": "/scala/connection_factory/#non-transport-specific-options",
            "text": "The driver is designed to support multiple transport libraries. This paragraph lists\noptions non-specific to any transport library.",
            "title": "Non-transport specific options"
        },
        {
            "location": "/scala/connection_factory/#frequently-used",
            "text": "host  Host name or IP address the database listens on.  Default value: no default value.       port  TCP port the database listens on.  Default value: no default value.       authenticator  Authenticator  instance performing authentication. See\n  authentication  chapter for details.  Default value: no default value.       dbName  The database name. if  None  is provided database name will be assumed to\n be the same as user name provide by the authenticator.  Default value:  None .       subscriberBufferCapacity  When streaming data from client to the database the driver can accumulate\n statements into batches for optimized execution. This parameter sets maximum\n number of statements that will be accumulated.  Default value:  100 .       stmtCacheConfig  Connection can cache prepared statements so that they can be reused when\n executed later on with different parameters. This paramaeter configures\n caching mechanism.  Possible values:   StmtCacheConfig . Disabled  \u2014 disables caching   StmtCacheConfig . Enabled  \u2014 enables caching.  Enabled  case class\n       has following fields:    capacity  Specifies maximum prepared statements that can be cached.      Default value:  Enabled ( capacity   =   100 ) .       writeTimeout  If socket write operation takes longer than this value, timeout error will be reported.  Default value:  Timeout ( 10. seconds ) .       ec  Execution context used by the connection to execute  Future  callbacks.  Default value:  scala . concurrent . ExecutionContext . global .",
            "title": "Frequently used"
        },
        {
            "location": "/scala/connection_factory/#other",
            "text": "typeConverters  Column values and statement arguments have some nominal Scala types that\n directly correspond to PostgreSQL types. Converters specified here will \n convert between the nominal type and the type specified by the client. \n For example,  int4  column is nominally represented by  PgInt4  class but \n because there is a converter that can convert between  PgInt4  and  Int \n whenever a  PgInt4  is expected client can supply an  Int .  Converters specified here supplement built-in converters.  Default value:  Vector . empty .       typeMappings  Statement arguments have some nominal types that directly correspond\n to PostgreSQL types. If non-nominal type is used as a statement argument\n there has to be a mapping between this type and a nominal type. For instance,\n  String  maps to  PgText  type.  Type mappings specified there supplement built-in mappings.",
            "title": "Other"
        },
        {
            "location": "/scala/connection_factory/#default-value-vectorempty",
            "text": "typeCodecs  Codecs for PostgreSQL types not supported by default by the driver.   Codecs specified here supplement built-in codecs.  Default value:  Vector . empty .       subscriberMinDemandRequestSize  When streaming data from a client to a database the driver requests statement\n argument sets from the client. This parameter defines minimum number of argument\n sets that the driver will request, each time the driver decides that it needs\n more argument sets.  Default value:  10 .",
            "title": "Default value: Vector.empty."
        },
        {
            "location": "/scala/connection_factory/#netty-transport-specific-options",
            "text": "channelFactory  Netty  ChannelFactory  that will be used to create a channel.  By default JDK NIO will be used which is supported on all platforms.\n Consider using platform specific native netty transport if your platform\n supports any. See  this \n page for details.  Default value:  new   NioChannelFactory       eventLoopGroup  Netty  EventLoopGroup  which will be used to handle events for the channel.  By default JDK NIO will be used which is supported on all platforms.\n Consider using platform specific native netty transport if your platform\n supports any. See  this \n page for details.  Default value:  new   NioEventLoopGroup .       channelOptions  Netty channel options.  CONNECT_TIMEOUT_MILLIS  is always ignored because it's overridden by\n timeout value passed to factory's  connection()  method. Other than that,\n you can set any netty channel option here.  Default values:   SO_KEEPALIVE = true",
            "title": "Netty transport specific options"
        },
        {
            "location": "/scala/connection_factory/#examples",
            "text": "Code in the snippet below creates a connection factory setting transport independent writeTimeout  and  subscriberBufferCapacity  options and also setting netty-specific channelOptions  option.  import   io.rdbc.pgsql.transport.netty.ChannelOptions._  import   io.rdbc.pgsql.transport.netty.NettyPgConnectionFactory  import   io.rdbc.pgsql.transport.netty.NettyPgConnectionFactory.Config  import   io.rdbc.pgsql.core.auth.Auth  import   io.rdbc.sapi.Timeout  import   io.netty.channel.ChannelOption._  import   scala.concurrent.duration._  val   cf   =   { \n   NettyPgConnectionFactory ( \n     Config ( \n       host   =   \"pg.example.com\" , \n       port   =   5432 , \n       authenticator   =   Auth . password ( \"user\" ,   \"pass\" ), \n       writeTimeout   =   Timeout ( 5. seconds ), \n       subscriberBufferCapacity   =   1000 , \n       channelOptions   =   Vector ( \n         SO_KEEPALIVE   ->   true , \n         WRITE_SPIN_COUNT   ->   3 \n       ) \n     ) \n   )  }",
            "title": "Examples"
        },
        {
            "location": "/scala/authentication/",
            "text": "The driver supports PostgreSQL authentication methods with \nAuthenticator\n\nimplementations it provides. \nAuthenticator\n instances can be obtained\nusing methods of \nAuth\n factory object and can be passed when creating\nconnection factory configuration as follows:\n\n\nval\n \nconfig\n \n=\n \nNettyPgConnectionFactory\n.\nConfig\n(\n\n       \nhost\n \n=\n \n\"pg.example.com\"\n,\n\n       \nport\n \n=\n \n5432\n,\n\n\n       \nauthenticator\n \n=\n \nAuth\n.\npassword\n(\n\"user\"\n,\n \n\"pass\"\n),\n\n\n       \n/* other options */\n\n      \n)\n\n\n\n\n\n\nProvided authenticators\n\u00b6\n\n\n\n\n\n\nPasswordAuthenticator\n\n\nFactory method: \nAuth\n.\npassword\n\n\nThis authenticator covers \npassword\n and \nmd5\n authentication methods\n described in PostgreSQL documentation \nhere\n.",
            "title": "Authentication"
        },
        {
            "location": "/scala/authentication/#provided-authenticators",
            "text": "PasswordAuthenticator  Factory method:  Auth . password  This authenticator covers  password  and  md5  authentication methods\n described in PostgreSQL documentation  here .",
            "title": "Provided authenticators"
        },
        {
            "location": "/scala/data_types/",
            "text": "General type mapping is described in rdbc documentation\n\nhere\n. Said chapter refers\nto the types by their standard names. This section describes type mapping using\nPostgreSQL type names.\n\n\nType mapping\n\u00b6\n\n\nFollowing table lists mapping between Scala and supported PostgreSQL types.\n\n\n\n\n\n\n\n\nPostgreSQL name\n\n\nScala type\n\n\n\n\n\n\n\n\n\n\nchar\n\n\nString\n\n\n\n\n\n\nvarchar\n\n\nString\n\n\n\n\n\n\ntext\n\n\nString\n\n\n\n\n\n\nbytea\n\n\nscodec.bits.ByteVector\n\n\n\n\n\n\nbool\n\n\nBoolean\n\n\n\n\n\n\nnumeric\n\n\nio.rdbc.sapi.DecimalNumber\n\n\n\n\n\n\nfloat4\n\n\nFloat\n\n\n\n\n\n\nfloat8\n\n\nDouble\n\n\n\n\n\n\nint2\n\n\nShort\n\n\n\n\n\n\nint4\n\n\nInt\n\n\n\n\n\n\nint8\n\n\nLong\n\n\n\n\n\n\ndate\n\n\njava.time.LocalDate\n\n\n\n\n\n\ntime\n\n\njava.time.LocalTime\n\n\n\n\n\n\ntimestamp\n\n\njava.time.Instant\n\n\n\n\n\n\ntimestamp with time zone\n\n\njava.time.ZonedDateTime\n\n\n\n\n\n\nuuid\n\n\njava.util.UUID",
            "title": "Data types"
        },
        {
            "location": "/scala/data_types/#type-mapping",
            "text": "Following table lists mapping between Scala and supported PostgreSQL types.     PostgreSQL name  Scala type      char  String    varchar  String    text  String    bytea  scodec.bits.ByteVector    bool  Boolean    numeric  io.rdbc.sapi.DecimalNumber    float4  Float    float8  Double    int2  Short    int4  Int    int8  Long    date  java.time.LocalDate    time  java.time.LocalTime    timestamp  java.time.Instant    timestamp with time zone  java.time.ZonedDateTime    uuid  java.util.UUID",
            "title": "Type mapping"
        },
        {
            "location": "/scala/exceptions/",
            "text": "The table below lists SQL state codes and exceptions that map to them. Every\ndriver exception class extends some rdbc exception type. You can extract\ninformation specific to PostgreSQL from the driver-specific exceptions.\n\n\n\n\n\n\n\n\nSQL state\n(X means any digit)\n\n\nDriver exception type\n\n\nrdbc exception type\n\n\n\n\n\n\n\n\n\n\n42501\n\n\nPgUnauthorizedException\n\n\nUnauthorizedException\n\n\n\n\n\n\n57014\n\n\nPgTimeoutException\n\n\nTimeoutException\n\n\n\n\n\n\n28XXX\n\n\nPgAuthFailureException\n\n\nAuthFailureException\n\n\n\n\n\n\n42XXX\n\n\nPgInvalidQueryException\n\n\nInvalidQueryException\n\n\n\n\n\n\n23XXX\n\n\nPgConstraintViolationException\n\n\nConstraintViolationException\n\n\n\n\n\n\nany other\n\n\nPgUncategorizedStatusDataException\n\n\nUncategorizedRdbcException\n\n\n\n\n\n\n\n\nThe driver also defines a number of exceptions that don't map to any SQL state\ncodes. For complete list see \nthe scaladoc\n.",
            "title": "Exceptions"
        },
        {
            "location": "/java/java/",
            "text": "Java API is ready but not yet documented.",
            "title": "Java API user guide"
        },
        {
            "location": "/developer/",
            "text": "Developer documentation is not ready yet.",
            "title": "Developer guide"
        },
        {
            "location": "/privacy/",
            "text": "Data collection\n\u00b6\n\n\nThis site uses Google Analytics to collect information. No personally identifiable\ninformation is collected. This site uses Google Analytics IP address anonymization feature.\n\n\nData processing\n\u00b6\n\n\nThe site owner uses the collected data to understand how many people visit\nthe site pages and where they came from.\n\n\nOpt-out from tracking\n\u00b6\n\n\nClick \nhere\n to opt-out of the\ntracking. This will create a cookie to remember the opt-out for your browser.",
            "title": "Privacy policy"
        },
        {
            "location": "/privacy/#data-collection",
            "text": "This site uses Google Analytics to collect information. No personally identifiable\ninformation is collected. This site uses Google Analytics IP address anonymization feature.",
            "title": "Data collection"
        },
        {
            "location": "/privacy/#data-processing",
            "text": "The site owner uses the collected data to understand how many people visit\nthe site pages and where they came from.",
            "title": "Data processing"
        },
        {
            "location": "/privacy/#opt-out-from-tracking",
            "text": "Click  here  to opt-out of the\ntracking. This will create a cookie to remember the opt-out for your browser.",
            "title": "Opt-out from tracking"
        }
    ]
}