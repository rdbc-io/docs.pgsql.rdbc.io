{
    "docs": [
        {
            "location": "/", 
            "text": "Warning\n\n\nrdbc-pgsql project and this documentation is still a work in progress.\nIt's not ready yet for production use.\n\n\n\n\nWhat is rdbc-pgsql?\n\n\nrdbc-pgsql is a \nnetty\n based \nrdbc\n driver\nfor PostgreSQL allowing asynchronous communication with the database in Scala\nand Java languages.\n\n\nrdbc API\n\n\nYou'll be using this PostgreSQL driver via the database vendor agnostic API which\nusage is not covered by this documentation. This guide describes things that\nare specific to the driver itself. Please head to the \nAPI documentation site\n\nfor detailed information on API usage and general rdbc concepts.\n\n\nSupported PostrgreSQL versions\n\n\nThe driver aims to support three latest stable PostgreSQL versions. Currently\nit means supporting PostgreSQL 9.6.x, 9.5.x and 9.4.x. The driver is tested\nagainst only these three versions but in fact, it should work with all versions \nsince 7.4.\n\n\nGetting help\n\n\nJoin \nrdbc-io/rdbc\n gitter channel for \nquestions and any kind of discussion about rdbc and the driver.\n\n\nSee also \nrdbc\n\ntag on StackOverflow.\n\n\nLicense\n\n\nrdbc-pgsql is an open source software licensed under\n\nApache License 2.0\n.", 
            "title": "Introduction"
        }, 
        {
            "location": "/#what-is-rdbc-pgsql", 
            "text": "rdbc-pgsql is a  netty  based  rdbc  driver\nfor PostgreSQL allowing asynchronous communication with the database in Scala\nand Java languages.", 
            "title": "What is rdbc-pgsql?"
        }, 
        {
            "location": "/#rdbc-api", 
            "text": "You'll be using this PostgreSQL driver via the database vendor agnostic API which\nusage is not covered by this documentation. This guide describes things that\nare specific to the driver itself. Please head to the  API documentation site \nfor detailed information on API usage and general rdbc concepts.", 
            "title": "rdbc API"
        }, 
        {
            "location": "/#supported-postrgresql-versions", 
            "text": "The driver aims to support three latest stable PostgreSQL versions. Currently\nit means supporting PostgreSQL 9.6.x, 9.5.x and 9.4.x. The driver is tested\nagainst only these three versions but in fact, it should work with all versions \nsince 7.4.", 
            "title": "Supported PostrgreSQL versions"
        }, 
        {
            "location": "/#getting-help", 
            "text": "Join  rdbc-io/rdbc  gitter channel for \nquestions and any kind of discussion about rdbc and the driver.  See also  rdbc \ntag on StackOverflow.", 
            "title": "Getting help"
        }, 
        {
            "location": "/#license", 
            "text": "rdbc-pgsql is an open source software licensed under Apache License 2.0 .", 
            "title": "License"
        }, 
        {
            "location": "/scala/installation/", 
            "text": "Warning\n\n\nrdbc-pgsql project and this documentation is still a work in progress.\nIt's not ready yet for production use.\n\n\n\n\nAdding rdbc-pgsql to your project\n\n\nrdbc and rdbc-pgsql JARs are published to\n\nMaven Central\n\nrepository. The library is currently available for Scala 2.11 and 2.12 and requires\nJava 8 runtime. rdbc-pgsql targets {{rdbc_version}} rdbc API version.\n\n\nSBT\n\n\nFor sbt projects, add the following to \nbuild.sbt\n:\n\n\nlibraryDependencies\n \n++=\n \nVector\n(\n\n  \nio.rdbc\n \n%%\n \nrdbc-api-scala\n \n%\n \n{{rdbc_version}}\n,\n\n  \nio.rdbc.pgsql\n \n%%\n \npgsql-transport-netty\n \n%\n \n{{version}}\n\n\n)\n\n\n\n\n\n\nGradle\n\n\nFor Gradle projects, add the following to the \ndependencies\n section of \nbuild.gradle\n:\n\n\nScala 2.12\n\n\ncompile\n \ngroup:\n \nio.rdbc\n,\n \nname:\n \nrdbc-api-scala_2.12\n,\n \nversion:\n \n{{rdbc_version}}\n\n\ncompile\n \ngroup:\n \nio.rdbc.pgsql\n,\n \nname:\n \npgsql-transport-netty_2.12\n,\n \nversion:\n \n{{version}}\n\n\n\n\n\n\nScala 2.11\n\n\ncompile\n \ngroup:\n \nio.rdbc\n,\n \nname:\n \nrdbc-api-scala_2.11\n,\n \nversion:\n \n{{rdbc_version}}\n\n\ncompile\n \ngroup:\n \nio.rdbc.pgsql\n,\n \nname:\n \npgsql-transport-netty_2.11\n,\n \nversion:\n \n{{version}}\n\n\n\n\n\n\nMaven\n\n\nFor Maven projects, add the following to the \ndependencies\n element of \npom.xml\n:\n\n\nScala 2.12\n\n\ndependency\n\n  \ngroupId\nio.rdbc\n/groupId\n\n  \nartifactId\nrdbc-api-scala_2.12\n/artifactId\n\n  \nversion\n{{rdbc_version}}\n/version\n\n\n/dependency\n\n\ndependency\n\n  \ngroupId\nio.rdbc.pgsql\n/groupId\n\n  \nartifactId\npgsql-transport-netty_2.12\n/artifactId\n\n  \nversion\n{{version}}\n/version\n\n\n/dependency\n\n\n\n\n\n\nScala 2.11\n\n\ndependency\n\n  \ngroupId\nio.rdbc\n/groupId\n\n  \nartifactId\nrdbc-api-scala_2.11\n/artifactId\n\n  \nversion\n{{rdbc_version}}\n/version\n\n\n/dependency\n\n\ndependency\n\n  \ngroupId\nio.rdbc.pgsql\n/groupId\n\n  \nartifactId\npgsql-transport-netty_2.11\n/artifactId\n\n  \nversion\n{{version}}\n/version\n\n\n/dependency", 
            "title": "Installation"
        }, 
        {
            "location": "/scala/installation/#adding-rdbc-pgsql-to-your-project", 
            "text": "rdbc and rdbc-pgsql JARs are published to Maven Central \nrepository. The library is currently available for Scala 2.11 and 2.12 and requires\nJava 8 runtime. rdbc-pgsql targets {{rdbc_version}} rdbc API version.", 
            "title": "Adding rdbc-pgsql to your project"
        }, 
        {
            "location": "/scala/installation/#sbt", 
            "text": "For sbt projects, add the following to  build.sbt :  libraryDependencies   ++=   Vector ( \n   io.rdbc   %%   rdbc-api-scala   %   {{rdbc_version}} , \n   io.rdbc.pgsql   %%   pgsql-transport-netty   %   {{version}}  )", 
            "title": "SBT"
        }, 
        {
            "location": "/scala/installation/#gradle", 
            "text": "For Gradle projects, add the following to the  dependencies  section of  build.gradle :  Scala 2.12  compile   group:   io.rdbc ,   name:   rdbc-api-scala_2.12 ,   version:   {{rdbc_version}}  compile   group:   io.rdbc.pgsql ,   name:   pgsql-transport-netty_2.12 ,   version:   {{version}}   Scala 2.11  compile   group:   io.rdbc ,   name:   rdbc-api-scala_2.11 ,   version:   {{rdbc_version}}  compile   group:   io.rdbc.pgsql ,   name:   pgsql-transport-netty_2.11 ,   version:   {{version}}", 
            "title": "Gradle"
        }, 
        {
            "location": "/scala/installation/#maven", 
            "text": "For Maven projects, add the following to the  dependencies  element of  pom.xml :  Scala 2.12  dependency \n   groupId io.rdbc /groupId \n   artifactId rdbc-api-scala_2.12 /artifactId \n   version {{rdbc_version}} /version  /dependency  dependency \n   groupId io.rdbc.pgsql /groupId \n   artifactId pgsql-transport-netty_2.12 /artifactId \n   version {{version}} /version  /dependency   Scala 2.11  dependency \n   groupId io.rdbc /groupId \n   artifactId rdbc-api-scala_2.11 /artifactId \n   version {{rdbc_version}} /version  /dependency  dependency \n   groupId io.rdbc.pgsql /groupId \n   artifactId pgsql-transport-netty_2.11 /artifactId \n   version {{version}} /version  /dependency", 
            "title": "Maven"
        }, 
        {
            "location": "/scala/connection_factory/", 
            "text": "Warning\n\n\nrdbc-pgsql project and this documentation is still a work in progress.\nIt's not ready yet for production use.\n\n\n\n\nAs rdbc documentation \nmentions\n,\nto use the API you need to construct a driver specific \nConnectionFactory\n \nimplementation. In rdbc-pgsql case, it's going to be\n\nNettyPgConnectionFactory\n.\n\n\nTo instantiate \nNettyPgConnectionFactory\n use its companion object's \napply\n\nmethod. This factory method accepts a configuration object \n \n\nNettyPgConnFactory#Config\n instance. Chapters below focus on providing\nthe configuration.\n\n\nSimple scenario\n\n\nTo create a configuration instance with default configuration options\nuse \nNettyPgConnFactory#Config\n's \napply\n method with \nhost\n, \nport\n and\n\nauthenticator\n parameters:\n\n\nimport\n \nio.rdbc.pgsql.transport.netty.NettyPgConnectionFactory\n\n\nimport\n \nio.rdbc.pgsql.transport.netty.NettyPgConnectionFactory.Config\n\n\nimport\n \nio.rdbc.pgsql.core.auth.Auth\n\n\n\nval\n \ncf\n \n=\n \nNettyPgConnectionFactory\n(\n\n  \nConfig\n(\n\n    \nhost\n \n=\n \nlocalhost\n,\n\n    \nport\n \n=\n \n5432\n,\n\n    \nauthenticator\n \n=\n \nAuth\n.\npassword\n(\nuser\n,\n \npass\n)\n\n  \n)\n\n\n)\n\n\n\n\n\n\nIf you want to tweak some configuration options (and most likely you do) read\nthe paragraph below.\n\n\nConfiguration options\n\n\nIf you want to override some of default option values use named parameters\nof \nConfig.apply\n method. In the example below \ndbName\n option is changed\nfrom default \nNone\n to \nSome(\ndb\n)\n. \n\n\nimport\n \nio.rdbc.pgsql.transport.netty.NettyPgConnectionFactory\n\n\nimport\n \nio.rdbc.pgsql.transport.netty.NettyPgConnectionFactory.Config\n\n\nimport\n \nio.rdbc.pgsql.core.auth.Auth\n\n\n\nval\n \ncf\n \n=\n \nNettyPgConnectionFactory\n(\nConfig\n(\n\n  \nhost\n \n=\n \nlocalhost\n,\n\n  \nport\n \n=\n \n5432\n,\n\n  \nauthenticator\n \n=\n \nAuth\n.\npassword\n(\nuser\n,\n \npass\n),\n\n  \ndbName\n \n=\n \nSome\n(\ndb\n)\n\n\n))\n\n\n\n\n\n\nFor other examples see \nexamples\n paragraph.\n\n\nThe paragraphs below list available configuration options.\n\n\nNon-transport specific options\n\n\nThe driver is designed to support multiple transport libraries. This paragraph lists\noptions non-specific to any transport library.\n\n\nFrequently used\n\n\n\n\n\n\nhost\n\n\nHost name or IP address the database listens on.\n\n\nDefault value: no default value.\n\n\n\n\n\n\n\n\n\n\n\n\nport\n\n\nTCP port the database listens on.\n\n\nDefault value: no default value.\n\n\n\n\n\n\n\n\n\n\n\n\nauthenticator\n\n\nAuthenticator\n instance performing authentication. See\n \nauthentication\n chapter for details.\n\n\nDefault value: no default value.\n\n\n\n\n\n\n\n\n\n\n\n\ndbName\n\n\nThe database name. if \nNone\n is provided database name will be assumed to\n be the same as user name provide by the authenticator.\n\n\nDefault value: \nNone\n.\n\n\n\n\n\n\n\n\n\n\n\n\nsubscriberBufferCapacity\n\n\nWhen streaming data from client to the database the driver can accumulate\n statements into batches for optimized execution. This parameter sets maximum\n number of statements that will be accumulated.\n\n\nDefault value: \n100\n.\n\n\n\n\n\n\n\n\n\n\n\n\nstmtCacheConfig\n\n\nConnection can cache prepared statements so that they can be reused when\n executed later on with different parameters. This paramaeter configures\n caching mechanism.\n\n\nPossible values:\n\n\n\n\nStmtCacheConfig\n.\nDisabled\n \n disables caching\n\n\n\n\nStmtCacheConfig\n.\nEnabled\n \n enables caching. \nEnabled\n case class\n       has following fields:\n\n\n\n\n\n\ncapacity\n\n\nSpecifies maximum prepared statements that can be cached.\n\n\n\n\n\n\n\n\n\n\nDefault value: \nEnabled\n(\ncapacity\n \n=\n \n100\n)\n.\n\n\n\n\n\n\n\n\n\n\n\n\nwriteTimeout\n\n\nIf socket write operation takes longer than this value, timeout error will be reported.\n\n\nDefault value: \nTimeout\n(\n10.\nseconds\n)\n.\n\n\n\n\n\n\n\n\n\n\n\n\nec\n\n\nExecution context used by the connection to execute \nFuture\n callbacks.\n\n\nDefault value: \nscala\n.\nconcurrent\n.\nExecutionContext\n.\nglobal\n.\n\n\n\n\n\n\nOther\n\n\n\n\n\n\ntypeConvertersProviders\n\n\nProviders providing converters that can do conversions between Scala types\n that represent database values and any other types. This option\n may be useful if you want to use Scala types not supported by default by rdbc.\n By default, conversions listed \nhere\n are provided.\n\n\nDefault value: \nVector\n(\nnew\n \nStandardTypeConvertersProvider\n)\n.\n\n\n\n\n\n\n\n\n\n\n\n\npgTypesProviders\n\n\nProviders providing definitions of PostgreSQL types and means to serialize\n and deserialize them. By default, types listed \nhere\n are supported\n and \nscodec\n library is used for serialization and deserialization.\n\n\nDefault value: \nVector\n(\nnew\n \nScodecPgTypesProvider\n)\n.\n\n\n\n\n\n\n\n\n\n\n\n\nmsgDecoderFactory\n\n\nA factory creating PostgreSQL protocol message decoder. By default,\n \nscodec\n library is used to decode messages.\n\n\nDefault value: \nnew\n \nScodecDecoderFactory\n.\n\n\n\n\n\n\n\n\n\n\n\n\nmsgEncoderFactory\n\n\nA factory creating PostgreSQL protocol message encoder. By default,\n \nscodec\n library is used to encode messages.\n\n\nDefault value: \nnew\n \nScodecEncoderFactory\n.\n\n\n\n\n\n\n\n\n\n\n\n\nsubscriberMinDemandRequestSize\n\n\nWhen streaming data from a client to a database the driver requests statement\n argument sets from the client. This parameter defines minimum number of argument\n sets that the driver will request, each time the driver decides that it needs\n more argument sets.\n\n\nDefault value: \n10\n.\n\n\n\n\n\n\nNetty transport specific options\n\n\n\n\n\n\nchannelFactory\n\n\nNetty \nChannelFactory\n that will be used to create a channel.\n\n\nBy default JDK NIO will be used which is supported on all platforms.\n Consider using platform specific native netty transport if your platform\n supports any. See \nthis\n\n page for details.\n\n\nDefault value: \nnew\n \nNioChannelFactory\n\n\n\n\n\n\n\n\n\n\n\n\neventLoopGroup\n\n\nNetty \nEventLoopGroup\n which will be used to handle events for the channel.\n\n\nBy default JDK NIO will be used which is supported on all platforms.\n Consider using platform specific native netty transport if your platform\n supports any. See \nthis\n\n page for details.\n\n\nDefault value: \nnew\n \nNioEventLoopGroup\n.\n\n\n\n\n\n\n\n\n\n\n\n\nchannelOptions\n\n\nNetty channel options.\n\n\nCONNECT_TIMEOUT_MILLIS\n is always ignored because it's overridden by\n timeout value passed to factory's \nconnection()\n method. Other than that,\n you can set any netty channel option here.\n\n\nDefault values:\n\n\n\n\nSO_KEEPALIVE = true\n\n\n\n\n\n\n\n\nExamples\n\n\nCode in the snippet below creates a connection factory setting transport independent\n\nwriteTimeout\n and \nsubscriberBufferCapacity\n options and also setting netty-specific\n\nchannelOptions\n option.\n\n\nimport\n \nio.rdbc.pgsql.transport.netty.ChannelOptions._\n\n\nimport\n \nio.rdbc.pgsql.transport.netty.NettyPgConnectionFactory\n\n\nimport\n \nio.rdbc.pgsql.transport.netty.NettyPgConnectionFactory.Config\n\n\nimport\n \nio.rdbc.pgsql.core.auth.Auth\n\n\nimport\n \nio.rdbc.sapi.Timeout\n\n\nimport\n \nio.netty.channel.ChannelOption._\n\n\nimport\n \nscala.concurrent.duration._\n\n\n\nval\n \ncf\n \n=\n \n{\n\n  \nNettyPgConnectionFactory\n(\n\n    \nConfig\n(\n\n      \nhost\n \n=\n \npg.example.com\n,\n\n      \nport\n \n=\n \n5432\n,\n\n      \nauthenticator\n \n=\n \nAuth\n.\npassword\n(\nuser\n,\n \npass\n),\n\n      \nwriteTimeout\n \n=\n \nTimeout\n(\n5.\nseconds\n),\n\n      \nsubscriberBufferCapacity\n \n=\n \n1000\n,\n\n      \nchannelOptions\n \n=\n \nVector\n(\n\n        \nSO_KEEPALIVE\n \n-\n \ntrue\n,\n\n        \nWRITE_SPIN_COUNT\n \n-\n \n3\n\n      \n)\n\n    \n)\n\n  \n)\n\n\n}", 
            "title": "Constructing connection factory"
        }, 
        {
            "location": "/scala/connection_factory/#simple-scenario", 
            "text": "To create a configuration instance with default configuration options\nuse  NettyPgConnFactory#Config 's  apply  method with  host ,  port  and authenticator  parameters:  import   io.rdbc.pgsql.transport.netty.NettyPgConnectionFactory  import   io.rdbc.pgsql.transport.netty.NettyPgConnectionFactory.Config  import   io.rdbc.pgsql.core.auth.Auth  val   cf   =   NettyPgConnectionFactory ( \n   Config ( \n     host   =   localhost , \n     port   =   5432 , \n     authenticator   =   Auth . password ( user ,   pass ) \n   )  )   If you want to tweak some configuration options (and most likely you do) read\nthe paragraph below.", 
            "title": "Simple scenario"
        }, 
        {
            "location": "/scala/connection_factory/#configuration-options", 
            "text": "If you want to override some of default option values use named parameters\nof  Config.apply  method. In the example below  dbName  option is changed\nfrom default  None  to  Some( db ) .   import   io.rdbc.pgsql.transport.netty.NettyPgConnectionFactory  import   io.rdbc.pgsql.transport.netty.NettyPgConnectionFactory.Config  import   io.rdbc.pgsql.core.auth.Auth  val   cf   =   NettyPgConnectionFactory ( Config ( \n   host   =   localhost , \n   port   =   5432 , \n   authenticator   =   Auth . password ( user ,   pass ), \n   dbName   =   Some ( db )  ))   For other examples see  examples  paragraph.  The paragraphs below list available configuration options.", 
            "title": "Configuration options"
        }, 
        {
            "location": "/scala/connection_factory/#non-transport-specific-options", 
            "text": "The driver is designed to support multiple transport libraries. This paragraph lists\noptions non-specific to any transport library.", 
            "title": "Non-transport specific options"
        }, 
        {
            "location": "/scala/connection_factory/#frequently-used", 
            "text": "host  Host name or IP address the database listens on.  Default value: no default value.       port  TCP port the database listens on.  Default value: no default value.       authenticator  Authenticator  instance performing authentication. See\n  authentication  chapter for details.  Default value: no default value.       dbName  The database name. if  None  is provided database name will be assumed to\n be the same as user name provide by the authenticator.  Default value:  None .       subscriberBufferCapacity  When streaming data from client to the database the driver can accumulate\n statements into batches for optimized execution. This parameter sets maximum\n number of statements that will be accumulated.  Default value:  100 .       stmtCacheConfig  Connection can cache prepared statements so that they can be reused when\n executed later on with different parameters. This paramaeter configures\n caching mechanism.  Possible values:   StmtCacheConfig . Disabled    disables caching   StmtCacheConfig . Enabled    enables caching.  Enabled  case class\n       has following fields:    capacity  Specifies maximum prepared statements that can be cached.      Default value:  Enabled ( capacity   =   100 ) .       writeTimeout  If socket write operation takes longer than this value, timeout error will be reported.  Default value:  Timeout ( 10. seconds ) .       ec  Execution context used by the connection to execute  Future  callbacks.  Default value:  scala . concurrent . ExecutionContext . global .", 
            "title": "Frequently used"
        }, 
        {
            "location": "/scala/connection_factory/#other", 
            "text": "typeConvertersProviders  Providers providing converters that can do conversions between Scala types\n that represent database values and any other types. This option\n may be useful if you want to use Scala types not supported by default by rdbc.\n By default, conversions listed  here  are provided.  Default value:  Vector ( new   StandardTypeConvertersProvider ) .       pgTypesProviders  Providers providing definitions of PostgreSQL types and means to serialize\n and deserialize them. By default, types listed  here  are supported\n and  scodec  library is used for serialization and deserialization.  Default value:  Vector ( new   ScodecPgTypesProvider ) .       msgDecoderFactory  A factory creating PostgreSQL protocol message decoder. By default,\n  scodec  library is used to decode messages.  Default value:  new   ScodecDecoderFactory .       msgEncoderFactory  A factory creating PostgreSQL protocol message encoder. By default,\n  scodec  library is used to encode messages.  Default value:  new   ScodecEncoderFactory .       subscriberMinDemandRequestSize  When streaming data from a client to a database the driver requests statement\n argument sets from the client. This parameter defines minimum number of argument\n sets that the driver will request, each time the driver decides that it needs\n more argument sets.  Default value:  10 .", 
            "title": "Other"
        }, 
        {
            "location": "/scala/connection_factory/#netty-transport-specific-options", 
            "text": "channelFactory  Netty  ChannelFactory  that will be used to create a channel.  By default JDK NIO will be used which is supported on all platforms.\n Consider using platform specific native netty transport if your platform\n supports any. See  this \n page for details.  Default value:  new   NioChannelFactory       eventLoopGroup  Netty  EventLoopGroup  which will be used to handle events for the channel.  By default JDK NIO will be used which is supported on all platforms.\n Consider using platform specific native netty transport if your platform\n supports any. See  this \n page for details.  Default value:  new   NioEventLoopGroup .       channelOptions  Netty channel options.  CONNECT_TIMEOUT_MILLIS  is always ignored because it's overridden by\n timeout value passed to factory's  connection()  method. Other than that,\n you can set any netty channel option here.  Default values:   SO_KEEPALIVE = true", 
            "title": "Netty transport specific options"
        }, 
        {
            "location": "/scala/connection_factory/#examples", 
            "text": "Code in the snippet below creates a connection factory setting transport independent writeTimeout  and  subscriberBufferCapacity  options and also setting netty-specific channelOptions  option.  import   io.rdbc.pgsql.transport.netty.ChannelOptions._  import   io.rdbc.pgsql.transport.netty.NettyPgConnectionFactory  import   io.rdbc.pgsql.transport.netty.NettyPgConnectionFactory.Config  import   io.rdbc.pgsql.core.auth.Auth  import   io.rdbc.sapi.Timeout  import   io.netty.channel.ChannelOption._  import   scala.concurrent.duration._  val   cf   =   { \n   NettyPgConnectionFactory ( \n     Config ( \n       host   =   pg.example.com , \n       port   =   5432 , \n       authenticator   =   Auth . password ( user ,   pass ), \n       writeTimeout   =   Timeout ( 5. seconds ), \n       subscriberBufferCapacity   =   1000 , \n       channelOptions   =   Vector ( \n         SO_KEEPALIVE   -   true , \n         WRITE_SPIN_COUNT   -   3 \n       ) \n     ) \n   )  }", 
            "title": "Examples"
        }, 
        {
            "location": "/scala/authentication/", 
            "text": "Warning\n\n\nrdbc-pgsql project and this documentation is still a work in progress.\nIt's not ready yet for production use.\n\n\n\n\nThe driver supports PostgreSQL authentication methods with \nAuthenticator\n\nimplementations it provides. \nAuthenticator\n instances can be obtained\nusing methods of \nAuth\n factory object and can be passed when creating\nconnection factory configuration as follows:\n\n\nval\n \nconfig\n \n=\n \nNettyPgConnectionFactory\n.\nConfig\n(\n\n       \nhost\n \n=\n \npg.example.com\n,\n\n       \nport\n \n=\n \n5432\n,\n\n\n       \nauthenticator\n \n=\n \nAuth\n.\npassword\n(\nuser\n,\n \npass\n),\n\n\n       \n/* other options */\n\n      \n)\n\n\n\n\n\n\nProvided authenticators\n\n\n\n\n\n\nPasswordAuthenticator\n\n\nFactory method: \nAuth\n.\npassword\n\n\nThis authenticator covers \npassword\n and \nmd5\n authentication methods\n described in PostgreSQL documentation \nhere\n.", 
            "title": "Authentication"
        }, 
        {
            "location": "/scala/authentication/#provided-authenticators", 
            "text": "PasswordAuthenticator  Factory method:  Auth . password  This authenticator covers  password  and  md5  authentication methods\n described in PostgreSQL documentation  here .", 
            "title": "Provided authenticators"
        }, 
        {
            "location": "/scala/data_types/", 
            "text": "Warning\n\n\nrdbc-pgsql project and this documentation is still a work in progress.\nIt's not ready yet for production use.\n\n\n\n\nGeneral type mapping is described in rdbc documentation\n\nhere\n. Said chapter refers\nto the types by their standard names. This section describes type mapping using\nPostgreSQL type names.\n\n\nType mapping\n\n\nFollowing table lists mapping between Scala and supported PostgreSQL types.\n\n\n\n\n\n\n\n\nPostgreSQL name\n\n\nStandard name\n\n\nScala type\n\n\n\n\n\n\n\n\n\n\nchar\n\n\nCHAR/NCHAR\n\n\nString\n\n\n\n\n\n\nvarchar\n\n\nVARCHAR/NVARCHAR\n\n\nString\n\n\n\n\n\n\ntext\n\n\n??? CLOB\n\n\nString\n\n\n\n\n\n\nbytea\n\n\n??? BLOB VARBINARY\n\n\nArray[Byte]\n\n\n\n\n\n\nbool\n\n\nBOOLEAN\n\n\nBoolean\n\n\n\n\n\n\nnumeric\n\n\nNUMERIC\n\n\nio.rdbc.sapi.SqlNumeric\n\n\n\n\n\n\nfloat4\n\n\nREAL\n\n\nFloat\n\n\n\n\n\n\nfloat8\n\n\nFLOAT\n\n\nDouble\n\n\n\n\n\n\nint2\n\n\nSMALLINT\n\n\nShort\n\n\n\n\n\n\nint4\n\n\nINTEGER\n\n\nInt\n\n\n\n\n\n\nint8\n\n\nBIGINT\n\n\nLong\n\n\n\n\n\n\ndate\n\n\nDATE\n\n\njava.time.LocalDate\n\n\n\n\n\n\ntime\n\n\nTIME\n\n\njava.time.LocalTime\n\n\n\n\n\n\ntimestamp\n\n\nTIMESTAMP\n\n\njava.time.LocalDateTime\n\n\n\n\n\n\ntimestamp with time zone\n\n\nTIMESTAMP WITH TIME ZONE\n\n\njava.time.Instant\n\n\n\n\n\n\nuuid\n\n\nnone\n\n\njava.util.UUID", 
            "title": "Data types"
        }, 
        {
            "location": "/scala/data_types/#type-mapping", 
            "text": "Following table lists mapping between Scala and supported PostgreSQL types.     PostgreSQL name  Standard name  Scala type      char  CHAR/NCHAR  String    varchar  VARCHAR/NVARCHAR  String    text  ??? CLOB  String    bytea  ??? BLOB VARBINARY  Array[Byte]    bool  BOOLEAN  Boolean    numeric  NUMERIC  io.rdbc.sapi.SqlNumeric    float4  REAL  Float    float8  FLOAT  Double    int2  SMALLINT  Short    int4  INTEGER  Int    int8  BIGINT  Long    date  DATE  java.time.LocalDate    time  TIME  java.time.LocalTime    timestamp  TIMESTAMP  java.time.LocalDateTime    timestamp with time zone  TIMESTAMP WITH TIME ZONE  java.time.Instant    uuid  none  java.util.UUID", 
            "title": "Type mapping"
        }, 
        {
            "location": "/scala/exceptions/", 
            "text": "Warning\n\n\nrdbc-pgsql project and this documentation is still a work in progress.\nIt's not ready yet for production use.\n\n\n\n\nThe table below lists SQL state codes and exceptions that map to them. Every\ndriver exception class extends some rdbc exception type. You can extract\ninformation specific to PostgreSQL from the driver-specific exceptions.\n\n\n\n\n\n\n\n\nSQL state\n(X means any digit)\n\n\nDriver exception type\n\n\nrdbc exception type\n\n\n\n\n\n\n\n\n\n\n42501\n\n\nPgUnauthorizedException\n\n\nUnauthorizedException\n\n\n\n\n\n\n57014\n\n\nPgTimeoutException\n\n\nTimeoutException\n\n\n\n\n\n\n28XXX\n\n\nPgAuthFailureException\n\n\nAuthFailureException\n\n\n\n\n\n\n42XXX\n\n\nPgInvalidQueryException\n\n\nInvalidQueryException\n\n\n\n\n\n\n23XXX\n\n\nPgConstraintViolationException\n\n\nConstraintViolationException\n\n\n\n\n\n\nany other\n\n\nPgUncategorizedStatusDataException\n\n\nUncategorizedRdbcException\n\n\n\n\n\n\n\n\nThe driver also defines a number of exceptions that don't map to any SQL state\ncodes. For complete list see \nthe scaladoc\n.", 
            "title": "Exceptions"
        }, 
        {
            "location": "/java/java/", 
            "text": "Warning\n\n\nrdbc-pgsql project and this documentation is still a work in progress.\nIt's not ready yet for production use.\n\n\n\n\nJava guide is not ready yet.", 
            "title": "Java API user guide"
        }, 
        {
            "location": "/developer/", 
            "text": "Warning\n\n\nrdbc-pgsql project and this documentation is still a work in progress.\nIt's not ready yet for production use.\n\n\n\n\nDeveloper documentation is not ready yet.", 
            "title": "Developer guide"
        }
    ]
}